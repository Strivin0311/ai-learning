# White-Box Adversarial Attacks
*Here's some resources about White-Box Adversarial Attacks*


#### Robust superpixel-guided attentional adversarial attack [`UNREAD`]

paper link: [here](http://openaccess.thecvf.com/content_CVPR_2020/papers/Dong_Robust_Superpixel-Guided_Attentional_Adversarial_Attack_CVPR_2020_paper.pdf)

citation: 
```bibtex
@inproceedings{dong2020robust,
  title={Robust superpixel-guided attentional adversarial attack},
  author={Dong, Xiaoyi and Han, Jiangfan and Chen, Dongdong and Liu, Jiayang and Bian, Huanyu and Ma, Zehua and Li, Hongsheng and Wang, Xiaogang and Zhang, Weiming and Yu, Nenghai},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12895--12904},
  year={2020}
}
```
    
#### Nesterov accelerated gradient and scale invariance for adversarial attacks [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/1908.06281)

citation: 
```bibtex
@article{lin2019nesterov,
  title={Nesterov accelerated gradient and scale invariance for adversarial attacks},
  author={Lin, Jiadong and Song, Chuanbiao and He, Kun and Wang, Liwei and Hopcroft, John E},
  journal={arXiv preprint arXiv:1908.06281},
  year={2019}
}
```


#### Shapeshifter: Robust physical adversarial attack on faster r-cnn object detector [`READ`]

paper link: [here](https://arxiv.org/pdf/1804.05810)

citation: 
```bibtex
@inproceedings{chen2019shapeshifter,
  title={Shapeshifter: Robust physical adversarial attack on faster r-cnn object detector},
  author={Chen, Shang-Tse and Cornelius, Cory and Martin, Jason and Chau, Duen Horng},
  booktitle={Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2018, Dublin, Ireland, September 10--14, 2018, Proceedings, Part I 18},
  pages={52--68},
  year={2019},
  organization={Springer}
}
```



#### Perceptual-sensitive gan for generating adversarial patches (PSGAN) [`READ`]

paper link: [here](https://ojs.aaai.org/index.php/AAAI/article/view/3893/3771)

citation: 
```bibtex
@inproceedings{liu2019perceptual,
  title={Perceptual-sensitive gan for generating adversarial patches},
  author={Liu, Aishan and Liu, Xianglong and Fan, Jiaxin and Ma, Yuqing and Zhang, Anlan and Xie, Huiyuan and Tao, Dacheng},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={1028--1035},
  year={2019}
}
```

#### Trust region based adversarial attack on neural networks [`UNREAD`]

paper link: [here](https://openaccess.thecvf.com/content_CVPR_2019/papers/Yao_Trust_Region_Based_Adversarial_Attack_on_Neural_Networks_CVPR_2019_paper.pdf)

citation: 
```bibtex
@inproceedings{yao2019trust,
  title={Trust region based adversarial attack on neural networks},
  author={Yao, Zhewei and Gholami, Amir and Xu, Peng and Keutzer, Kurt and Mahoney, Michael W},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={11350--11359},
  year={2019}
}
```
    
    
#### Robust physical-world attacks on deep learning visual classification (RP2) [`READ`]

paper link: [here](http://openaccess.thecvf.com/content_cvpr_2018/papers/Eykholt_Robust_Physical-World_Attacks_CVPR_2018_paper.pdf)

citation: 
```bibtex
@inproceedings{eykholt2018robust,
  title={Robust physical-world attacks on deep learning visual classification},
  author={Eykholt, Kevin and Evtimov, Ivan and Fernandes, Earlence and Li, Bo and Rahmati, Amir and Xiao, Chaowei and Prakash, Atul and Kohno, Tadayoshi and Song, Dawn},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1625--1634},
  year={2018}
}
```
    

#### Generating adversarial examples with adversarial networks (AdvGANs) [`READ`]

paper link: [here](https://arxiv.org/pdf/1801.02610)

citation: 
```bibtex
@article{xiao2018generating,
  title={Generating adversarial examples with adversarial networks},
  author={Xiao, Chaowei and Li, Bo and Zhu, Jun-Yan and He, Warren and Liu, Mingyan and Song, Dawn},
  journal={arXiv preprint arXiv:1801.02610},
  year={2018}
}
```

#### Synthesizing robust adversarial examples (EOT) [`READ`]

paper link: [here](http://proceedings.mlr.press/v80/athalye18b/athalye18b.pdf)

citation: 
```bibtex
@inproceedings{athalye2018synthesizing,
  title={Synthesizing robust adversarial examples},
  author={Athalye, Anish and Engstrom, Logan and Ilyas, Andrew and Kwok, Kevin},
  booktitle={International conference on machine learning},
  pages={284--293},
  year={2018},
  organization={PMLR}
}
```
    
#### Universal adversarial perturbations [`READ`]

paper link: [here](http://openaccess.thecvf.com/content_cvpr_2017/papers/Moosavi-Dezfooli_Universal_Adversarial_Perturbations_CVPR_2017_paper.pdf)

citation: 
```bibtex
@inproceedings{moosavi2017universal,
  title={Universal adversarial perturbations},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Fawzi, Omar and Frossard, Pascal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1765--1773},
  year={2017}
}
```
    
    

#### Adversarial transformation networks: Learning to generate adversarial examples (ATNs) [`READ`]

paper link: [here](https://arxiv.org/pdf/1703.09387.pdf)

citation: 
```bibtex
@article{baluja2017adversarial,
  title={Adversarial transformation networks: Learning to generate adversarial examples},
  author={Baluja, Shumeet and Fischer, Ian},
  journal={arXiv preprint arXiv:1703.09387},
  year={2017}
}
```

#### Adversarial patch [`READ`]

paper link: [here](https://arxiv.org/pdf/1712.09665.pdf)

citation: 
```bibtex
@article{brown2017adversarial,
  title={Adversarial patch},
  author={Brown, Tom B and Man{\'e}, Dandelion and Roy, Aurko and Abadi, Mart{\'\i}n and Gilmer, Justin},
  journal={arXiv preprint arXiv:1712.09665},
  year={2017}
}
```
    

#### Towards evaluating the robustness of neural networks (C&W) [`READ`]

paper link: [here](https://arxiv.org/pdf/1608.04644.pdf?source=post_page)

citation: 
```bibtex
@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 ieee symposium on security and privacy (sp)},
  pages={39--57},
  year={2017},
  organization={Ieee}
}
```

#### Towards deep learning models resistant to adversarial attacks (PGD) [`READ`]

paper link: [here](https://arxiv.org/pdf/1706.06083.pdf%E4%B8%AD%E6%9C%89%E4%BD%93%E7%8E%B0%EF%BC%8C%E4%BB%A5%E5%90%8E%E8%AF%B4%E5%88%B0CW%E6%94%BB%E5%87%BB%E5%86%8D%E7%BB%86%E8%AF%B4%E3%80%82)

citation: 
```bibtex
@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}
```
    

#### Adversarial examples in the physical world (BIM / LLCM) [`READ`]
paper link: [here](https://arxiv.org/pdf/1607.02533.pdf?utm_sourcesciontist.com&utm_mediumrefer&utm_campaignpromote)

citation: 
```bibtex
@misc{kurakin2016adversarial,
  title={Adversarial examples in the physical world},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy and others},
  year={2016}
}
```    

#### Adversarial machine learning at scale [`READ`]

paper link: [here](https://arxiv.org/pdf/1611.01236)

citation: 
```bibtex
@article{kurakin2016adversarial,
  title={Adversarial machine learning at scale},
  author={Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
  journal={arXiv preprint arXiv:1611.01236},
  year={2016}
}
```
    


#### Deepfool: a simple and accurate method to fool deep neural networks [`READ`]

paper link: [here](https://openaccess.thecvf.com/content_cvpr_2016/papers/Moosavi-Dezfooli_DeepFool_A_Simple_CVPR_2016_paper.pdf)

citation: 
```bibtex
@inproceedings{moosavi2016deepfool,
  title={Deepfool: a simple and accurate method to fool deep neural networks},
  author={Moosavi-Dezfooli, Seyed-Mohsen and Fawzi, Alhussein and Frossard, Pascal},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2574--2582},
  year={2016}
}
```

#### The limitations of deep learning in adversarial settings (JSMA) [`READ`]

paper link: [here](https://arxiv.org/pdf/1511.07528.pdf&xid=25657,15700023,15700124,15700149,15700186,15700191,15700201,15700237,15700242)

citation: 
```bibtex
@inproceedings{papernot2016limitations,
  title={The limitations of deep learning in adversarial settings},
  author={Papernot, Nicolas and McDaniel, Patrick and Jha, Somesh and Fredrikson, Matt and Celik, Z Berkay and Swami, Ananthram},
  booktitle={2016 IEEE European symposium on security and privacy (EuroS\&P)},
  pages={372--387},
  year={2016},
  organization={IEEE}
}
```
    

#### Explaining and harnessing adversarial examples (FGSM) [`READ`]

paper link: [here](https://arxiv.org/pdf/1412.6572.pdf)

citation: 
```bibtex
@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}
```
    
    