# Defences for Adversarial Attacks 
*Here's some resources about Defences for Adversarial Attacks*



#### Certified Adversarial Robustness via Randomized Smoothing [`READ`]

paper link: [here](http://proceedings.mlr.press/v97/cohen19c/cohen19c.pdf)

citation: 
```bibtex
@inproceedings{cohen2019certified,
  title={Certified adversarial robustness via randomized smoothing},
  author={Cohen, Jeremy and Rosenfeld, Elan and Kolter, Zico},
  booktitle={international conference on machine learning},
  pages={1310--1320},
  year={2019},
  organization={PMLR}
}
```



#### Adversarial Training and Robustness for Multiple Perturbations [`READ`]

paper link: [here](https://proceedings.neurips.cc/paper/2019/file/5d4ae76f053f8f2516ad12961ef7fe97-Paper.pdf)

citation: 
```bibtex
@article{tramer2019adversarial,
  title={Adversarial training and robustness for multiple perturbations},
  author={Tramer, Florian and Boneh, Dan},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}
```

#### Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples [`UNREAD`]

paper link: [here](http://proceedings.mlr.press/v80/athalye18a/athalye18a.pdf)

citation: 
```bibtex
@inproceedings{athalye2018obfuscated,
  title={Obfuscated gradients give a false sense of security: Circumventing defenses to adversarial examples},
  author={Athalye, Anish and Carlini, Nicholas and Wagner, David},
  booktitle={International conference on machine learning},
  pages={274--283},
  year={2018},
  organization={PMLR}
}
```
    
#### Provable defenses against adversarial examples via the convex outer adversarial polytope [`UNREAD`]

paper link: [here](http://proceedings.mlr.press/v80/wong18a/wong18a.pdf)

citation: 
```bibtex
@inproceedings{wong2018provable,
  title={Provable defenses against adversarial examples via the convex outer adversarial polytope},
  author={Wong, Eric and Kolter, Zico},
  booktitle={International conference on machine learning},
  pages={5286--5295},
  year={2018},
  organization={PMLR}
}
```
    

#### Ensemble adversarial training: Attacks and defenses [`UNREAD`]

paper link: [here](https://arxiv.org/pdf/1705.07204.pdf)

citation: 
```bibtex
@article{tramer2017ensemble,
  title={Ensemble adversarial training: Attacks and defenses},
  author={Tram{\`e}r, Florian and Kurakin, Alexey and Papernot, Nicolas and Goodfellow, Ian and Boneh, Dan and McDaniel, Patrick},
  journal={arXiv preprint arXiv:1705.07204},
  year={2017}
}
```
    

#### Detecting Adversarial Samples from Artifacts [`READ`]

paper link: [here](https://arxiv.org/pdf/1703.00410)

citation: 
```bibtex
@article{feinman2017detecting,
  title={Detecting adversarial samples from artifacts},
  author={Feinman, Reuben and Curtin, Ryan R and Shintre, Saurabh and Gardner, Andrew B},
  journal={arXiv preprint arXiv:1703.00410},
  year={2017}
}
```
    

#### Distillation as a defense to adversarial perturbations against deep neural networks [`READ`]

paper link: [here](https://arxiv.org/pdf/1511.04508.pdf&xid=25657,15700023,15700124,15700149,15700186,15700191,15700201,15700237,15700242)

citation: 
```bibtex
@inproceedings{papernot2016distillation,
  title={Distillation as a defense to adversarial perturbations against deep neural networks},
  author={Papernot, Nicolas and McDaniel, Patrick and Wu, Xi and Jha, Somesh and Swami, Ananthram},
  booktitle={2016 IEEE symposium on security and privacy (SP)},
  pages={582--597},
  year={2016},
  organization={IEEE}
}
```
    