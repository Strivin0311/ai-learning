# Model-based RL
*Here're some resources about Model-based RL*



#### Deep reinforcement learning in a handful of trials using probabilistic dynamics models

paper link: [here](https://proceedings.neurips.cc/paper_files/paper/2018/file/3de568f8597b94bda53149c7d7f5958c-Paper.pdf)

citation: 
```bibtex
@article{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}
```
    

#### Learning neural network policies with guided policy search under unknown dynamics

paper link: [here](https://proceedings.neurips.cc/paper_files/paper/2014/file/6766aa2750c19aad2fa1b32f36ed4aee-Paper.pdf)

citation: 
```bibtex
@article{levine2014learning,
  title={Learning neural network policies with guided policy search under unknown dynamics},
  author={Levine, Sergey and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}
```

#### Variational policy search via trajectory optimization

paper link: [here](https://proceedings.neurips.cc/paper_files/paper/2013/file/38af86134b65d0f10fe33d30dd76442e-Paper.pdf)

citation: 
```bibtex
@article{levine2013variational,
  title={Variational policy search via trajectory optimization},
  author={Levine, Sergey and Koltun, Vladlen},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}
```
    
    

### Survey

#### Model-based reinforcement learning: A survey

paper link: [here](https://www.nowpublishers.com/article/DownloadSummary/MAL-086)

citation: 
```bibtex
@article{moerland2023model,
  title={Model-based reinforcement learning: A survey},
  author={Moerland, Thomas M and Broekens, Joost and Plaat, Aske and Jonker, Catholijn M and others},
  journal={Foundations and Trends{\textregistered} in Machine Learning},
  volume={16},
  number={1},
  pages={1--118},
  year={2023},
  publisher={Now Publishers, Inc.}
}
```
    