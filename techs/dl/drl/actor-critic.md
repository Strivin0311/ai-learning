# Actor-Critic based RL (AC)
*Here're some resources about Actor-Critic based RL*


#### Soft actor-critic for discrete action settings

paper link: [here](https://arxiv.org/pdf/1910.07207)

citation: 
```bibtex
@article{christodoulou2019soft,
  title={Soft actor-critic for discrete action settings},
  author={Christodoulou, Petros},
  journal={arXiv preprint arXiv:1910.07207},
  year={2019}
}
```
    

#### Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor

paper link: [here](http://proceedings.mlr.press/v80/haarnoja18b/haarnoja18b.pdf)

citation: 
```bibtex
@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}
```
    


#### Soft actor-critic algorithms and applications

paper link: [here](https://arxiv.org/pdf/1812.05905)

citation: 
```bibtex
@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}
```


#### Addressing function approximation error in actor-critic methods

paper link: [here](http://proceedings.mlr.press/v80/fujimoto18a/fujimoto18a.pdf)

citation: 
```bibtex
@inproceedings{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Hoof, Herke and Meger, David},
  booktitle={International conference on machine learning},
  pages={1587--1596},
  year={2018},
  organization={PMLR}
}
```
    

#### Asynchronous methods for deep reinforcement learning (A2C and A3C)

paper link: [here](http://proceedings.mlr.press/v48/mniha16.pdf)

citation: 
```bibtex
@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016},
  organization={PMLR}
}
```
    

#### Sample efficient actor-critic with experience replay

paper link: [here](https://arxiv.org/pdf/1611.01224)

citation: 
```bibtex
@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}
```
    