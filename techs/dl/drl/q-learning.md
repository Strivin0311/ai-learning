# Q-Learning based RL
*Here're some resources about Q-Learning based RL*


#### Double Gumbel Q-Learning

paper link: [here](https://openreview.net/pdf?id=UdaTyy0BNB)

citation: 
```bibtex
@inproceedings{hui2023double,
  title={Double Gumbel Q-Learning},
  author={Hui, David Yu-Tung and Courville, Aaron and Bacon, Pierre-Luc},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}
```



#### Rainbow: Combining improvements in deep reinforcement learning

paper link: [here](https://ojs.aaai.org/index.php/AAAI/article/download/11796/11655)

citation: 
```bibtex
@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}
```



#### Decoupled weight decay regularization

paper link: [here](https://arxiv.org/pdf/1711.05101.pdf])

citation: 
```bibtex
@article{loshchilov2017decoupled,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}
```
    


#### Noisy networks for exploration

paper link: [here](https://arxiv.org/pdf/1706.10295.pdf)

citation: 
```bibtex
@article{fortunato2017noisy,
  title={Noisy networks for exploration},
  author={Fortunato, Meire and Azar, Mohammad Gheshlaghi and Piot, Bilal and Menick, Jacob and Osband, Ian and Graves, Alex and Mnih, Vlad and Munos, Remi and Hassabis, Demis and Pietquin, Olivier and others},
  journal={arXiv preprint arXiv:1706.10295},
  year={2017}
}
```
    


#### A distributional perspective on reinforcement learning

paper link: [here](http://proceedings.mlr.press/v70/bellemare17a/bellemare17a.pdf)

citation: 
```bibtex
@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={449--458},
  year={2017},
  organization={PMLR}
}
```


 #### A deeper look at experience replay

paper link: [here](https://arxiv.org/pdf/1712.01275)

citation: 
```bibtex
@article{zhang2017deeper,
  title={A deeper look at experience replay},
  author={Zhang, Shangtong and Sutton, Richard S},
  journal={arXiv preprint arXiv:1712.01275},
  year={2017}
}
```
       


#### Dueling network architectures for deep reinforcement learning

paper link: [here](http://proceedings.mlr.press/v48/wangf16.pdf)

citation: 
```bibtex
@inproceedings{wang2016dueling,
  title={Dueling network architectures for deep reinforcement learning},
  author={Wang, Ziyu and Schaul, Tom and Hessel, Matteo and Hasselt, Hado and Lanctot, Marc and Freitas, Nando},
  booktitle={International conference on machine learning},
  pages={1995--2003},
  year={2016},
  organization={PMLR}
}
```
    


#### Deep reinforcement learning with double q-learning

paper link: [here](https://ojs.aaai.org/index.php/AAAI/article/download/10295/10154)


here's a [notebook](./notebooks/DQN_Pong.ipynb) about the DQN algorithm and its variants like Doulbe-DQN, Dueling-DQN, etc on the PingPong task in gym

citation: 
```bibtex
@inproceedings{van2016deep,
  title={Deep reinforcement learning with double q-learning},
  author={Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={30},
  number={1},
  year={2016}
}
```

#### Prioritized experience replay

paper link: [here](https://arxiv.org/pdf/1511.05952.pdf)

citation: 
```bibtex
@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}
```


#### Human-level control through deep reinforcement learning

paper link: [here](https://training.incf.org/sites/default/files/2023-05/Human-level%20control%20through%20deep%20reinforcement%20learning.pdf)


here's a [notebook](./notebooks/REINFORCE_CartPole.ipynb) about the REINFORCE algorithm on the CartPole task in gym

here's a [notebook](./notebooks/CEM_CartPole.ipynb) about the CEM algorithm on the CartPole task in gym

citation: 
```bibtex
@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}
```


#### Playing atari with deep reinforcement learning

paper link: [here](https://arxiv.org/pdf/1312.5602.pdf)

here's a [notebook](./notebooks/TabQL_FrozenLake.ipynb) about the original Q-table learning on the FrozenLake task in gym


citation: 
```bibtex
@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}
```


    
    