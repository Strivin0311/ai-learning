# Policy-Gradient based RL
*Here're some resources about Policy-Gradient based RL*


#### Connected Superlevel Set in (Deep) Reinforcement Learning and its Application to Minimax Theorems

paper link: [here](https://arxiv.org/pdf/2303.12981)

citation: 
```bibtex
@article{zeng2023connected,
  title={Connected Superlevel Set in (Deep) Reinforcement Learning and its Application to Minimax Theorems},
  author={Zeng, Sihan and Doan, Thinh T and Romberg, Justin},
  journal={arXiv preprint arXiv:2303.12981},
  year={2023}
}
```
    


#### Simple random search provides a competitive approach to reinforcement learning

paper link: [here](https://arxiv.org/pdf/1803.07055.pdf)

citation: 
```bibtex
@article{mania2018simple,
  title={Simple random search provides a competitive approach to reinforcement learning},
  author={Mania, Horia and Guy, Aurelia and Recht, Benjamin},
  journal={arXiv preprint arXiv:1803.07055},
  year={2018}
}
```
    


#### Reinforcement learning with deep energy-based policies

paper link: [here](http://proceedings.mlr.press/v70/haarnoja17a/haarnoja17a.pdf)

citation: 
```bibtex
@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1352--1361},
  year={2017},
  organization={PMLR}
}
```


#### Scalable trust-region method for deep reinforcement learning using kronecker-factored approximation

paper link: [here](https://proceedings.neurips.cc/paper/2017/file/361440528766bbaaaa1901845cf4152b-Paper.pdf)

citation: 
```bibtex
@article{wu2017scalable,
  title={Scalable trust-region method for deep reinforcement learning using kronecker-factored approximation},
  author={Wu, Yuhuai and Mansimov, Elman and Grosse, Roger B and Liao, Shun and Ba, Jimmy},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
```
    


#### Proximal policy optimization algorithms (PPO)

paper link: [here](https://arxiv.org/pdf/1707.06347.pdf)

citation: 
```bibtex
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
```


#### Trust region policy optimization (TRPO)

paper link: [here](http://proceedings.mlr.press/v37/schulman15.pdf)

citation: 
```bibtex
@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015},
  organization={PMLR}
}
```

#### Continuous control with deep reinforcement learning

paper link: [here](https://arxiv.org/pdf/1509.02971.pdf)

citation: 
```bibtex
@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}
```

#### Learning Tetris using the noisy cross-entropy method

paper link: [here](https://www.academia.edu/download/31975697/SzitaLorincz05Learning.pdf)

citation: 
```bibtex
@article{szita2006learning,
  title={Learning Tetris using the noisy cross-entropy method},
  author={Szita, Istv{\'a}n and L{\"o}rincz, Andr{\'a}s},
  journal={Neural computation},
  volume={18},
  number={12},
  pages={2936--2941},
  year={2006},
  publisher={MIT Press}
}
```
    
    
    
    